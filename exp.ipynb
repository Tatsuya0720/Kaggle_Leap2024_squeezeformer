{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# deep learning related\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sys.path.append(\"./\")\n",
    "from leap_feature import LeapData, Feature\n",
    "from leap_dataset import LeepDataset\n",
    "from leap_network import LeapNetwork\n",
    "from leap_graph import graph_plot\n",
    "from config import ExpConfig\n",
    "\n",
    "folder_name = ExpConfig().data_splitfolder_name\n",
    "\n",
    "\n",
    "# seed related\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定クラスの定義\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 1024\n",
    "        self.num_epochs = 100\n",
    "        self.n_dataset = 150\n",
    "        self.learning_rate = 0.0005\n",
    "        self.weight_decay = 0.01\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # self.model_path = \"./model.pth\"\n",
    "\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "\n",
    "weight = pickle.load(open(\"./weight.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "\n",
    "train_filenames = pickle.load(\n",
    "    open(\n",
    "        os.path.join(\n",
    "            \"../../standarised_preprocess/\", folder_name, \"train_filenames.pkl\"\n",
    "        ),\n",
    "        \"rb\",\n",
    "    )\n",
    ")\n",
    "data_path = [\"../../inputs/float32_numpy/{}\".format(f) for f in train_filenames]\n",
    "\n",
    "load_datas = []\n",
    "\n",
    "for i, path in tqdm(enumerate(data_path)):\n",
    "    if i == 0:\n",
    "        load_datas.append(np.load(path))\n",
    "    else:\n",
    "        load_datas.append(np.load(path))\n",
    "\n",
    "load_data = np.concatenate(load_datas, axis=0)\n",
    "del load_datas\n",
    "gc.collect()\n",
    "\n",
    "train_index, valid_index = train_test_split(\n",
    "    range(len(load_data)), test_size=0.2, random_state=42\n",
    ")\n",
    "tmp_valid_load_data = load_data[valid_index, :]\n",
    "scaler = pickle.load(open(\"../../standarised_preprocess/scaler.pkl\", \"rb\"))\n",
    "train_load_data = LeapData(load_data[train_index, :], train=False, scaler=scaler)\n",
    "valid_load_data = LeapData(load_data[valid_index, :], train=False, scaler=scaler)\n",
    "\n",
    "train_load_data = LeepDataset(train_load_data)\n",
    "valid_load_data = LeepDataset(valid_load_data)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_load_data,\n",
    "    batch_size=cfg.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=14,\n",
    "    pin_memory=True,\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_load_data,\n",
    "    batch_size=cfg.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=14,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル定義\n",
    "model = LeapNetwork()\n",
    "model.to(cfg.device)\n",
    "\n",
    "means = scaler.mean_\n",
    "stds = scaler.scale_\n",
    "target_means = means[556:]\n",
    "target_stds = np.sqrt(scaler.var_[556:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化定義\n",
    "from sklearn.metrics import r2_score as r2_metrics\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "def flatten_(t):\n",
    "    y0_y5 = t[:, :6, :].reshape(-1, 6 * 60)\n",
    "    y6 = t[:, 6:, 0].reshape(-1, 8)\n",
    "    output = np.concatenate((y0_y5, y6), axis=1)\n",
    "    return output\n",
    "\n",
    "\n",
    "def custom_r2(y_pred, y_true):\n",
    "    y_true = y_true * stds[556:].reshape(1, -1) + means[556:].reshape(1, -1)\n",
    "    y_pred = y_pred * target_stds.reshape(1, -1) + target_means.reshape(1, -1)\n",
    "    y_true = y_true * weight\n",
    "    y_pred = y_pred * weight\n",
    "    return 1 - np.sum((y_true - y_pred) ** 2) / np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "\n",
    "\n",
    "def one_column_r2(y_pred, y_true, i, weight):\n",
    "    y_true = y_true * stds[556 + i] + means[556 + i]\n",
    "    y_pred = y_pred * target_stds[i] + target_means[i]\n",
    "\n",
    "    y_true = y_true * weight\n",
    "    y_pred = y_pred * weight\n",
    "    return r2_metrics(y_true, y_pred)\n",
    "\n",
    "\n",
    "def ignore_one_column_r2(y_pred, y_true, i, weight, ptend_0002=False):\n",
    "    if ptend_0002:\n",
    "        y_pred = -y_pred * weight / 1200.0\n",
    "    else:\n",
    "        y_pred = y_pred * target_stds[i] + target_means[i]\n",
    "        y_pred = y_pred * weight\n",
    "\n",
    "    y_true = y_true * stds[556 + i] + means[556 + i]\n",
    "    y_true = y_true * weight\n",
    "    return r2_metrics(y_true, y_pred)\n",
    "\n",
    "\n",
    "class R2Score(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        return custom_r2(y_pred, y_true)\n",
    "\n",
    "    def __call__(self, y_pred, y_true):\n",
    "\n",
    "        return custom_r2(y_pred, y_true)\n",
    "\n",
    "\n",
    "class CustomeWeightedLoss(torch.nn.Module):\n",
    "    def __init__(self, weight) -> None:\n",
    "        super().__init__()\n",
    "        self.criterion = torch.nn.MSELoss()\n",
    "        self.mask = torch.ones(60 * 14).cuda()\n",
    "        self.mask = self.mask.reshape(1, 14, 60)\n",
    "        self.mask[:, 2, :28] = 0.0\n",
    "        self.weight = torch.tensor(weight[:, :-8].astype(np.float32))\n",
    "        self.weight = self.weight.reshape(1, 6, 60)\n",
    "        self.weight = torch.cat([self.weight, torch.ones(1, 8, 60)], dim=1)\n",
    "        self.weight = torch.where(\n",
    "            self.weight == 0, torch.tensor(0.0), torch.tensor(1.0)\n",
    "        ).cuda()\n",
    "        self.weight = self.weight.reshape(1, 14, 60)\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_pred = y_pred * self.mask\n",
    "        # y_pred = y_pred * self.weight\n",
    "\n",
    "        return self.criterion(y_pred, y_true)\n",
    "\n",
    "\n",
    "criterion = CustomeWeightedLoss(weight=weight)\n",
    "eval_criterion = R2Score()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=cfg.learning_rate, weight_decay=cfg.weight_decay\n",
    ")\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=10,\n",
    "    num_training_steps=cfg.num_epochs * len(train_loader),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = Feature.target\n",
    "\n",
    "best_r2 = -np.inf\n",
    "best_model = None\n",
    "\n",
    "criterion_weight = torch.ones_like(\n",
    "    torch.from_numpy(weight[0, :-8].astype(np.float32)).to(torch.float32)\n",
    ").reshape(1, -1)\n",
    "criterion_weight = criterion_weight.to(cfg.device).to(torch.float32)\n",
    "\n",
    "train_r2_scores = {}\n",
    "valid_r2_scores = {}\n",
    "\n",
    "for epoch in range(cfg.num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    ignore_index = []\n",
    "    train_preds = []\n",
    "    train_labels = []\n",
    "    valid_preds = []\n",
    "    valid_labels = []\n",
    "\n",
    "    tq = tqdm(total=len(train_loader))\n",
    "    tq.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "    current_loss = 0.0\n",
    "    r2_score = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        g0 = data[\"g0\"].to(cfg.device).to(torch.float32)\n",
    "        g1 = data[\"g1\"].to(cfg.device).to(torch.float32)\n",
    "        g2 = data[\"g2\"].to(cfg.device).to(torch.float32)\n",
    "        g3 = data[\"g3\"].to(cfg.device).to(torch.float32)\n",
    "        g4 = data[\"g4\"].to(cfg.device).to(torch.float32)\n",
    "        g5 = data[\"g5\"].to(cfg.device).to(torch.float32)\n",
    "        g6 = data[\"g6\"].to(cfg.device).to(torch.float32)\n",
    "        g7 = data[\"g7\"].to(cfg.device).to(torch.float32)\n",
    "        g8 = data[\"g8\"].to(cfg.device).to(torch.float32)\n",
    "        g_else = data[\"g_else\"].to(cfg.device).to(torch.float32)\n",
    "\n",
    "        y0 = data[\"y0\"].to(cfg.device).unsqueeze(1)\n",
    "        y1 = data[\"y1\"].to(cfg.device).unsqueeze(1)\n",
    "        y2 = data[\"y2\"].to(cfg.device).unsqueeze(1)\n",
    "        y3 = data[\"y3\"].to(cfg.device).unsqueeze(1)\n",
    "        y4 = data[\"y4\"].to(cfg.device).unsqueeze(1)\n",
    "        y5 = data[\"y5\"].to(cfg.device).unsqueeze(1)\n",
    "        y6 = data[\"y6\"].to(cfg.device).unsqueeze(-1).repeat(1, 1, 60)\n",
    "        y = torch.cat([y0, y1, y2, y3, y4, y5, y6], dim=1).to(torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        unet_output = model(g0, g1, g2, g3, g4, g5, g6, g7, g8, g_else)\n",
    "\n",
    "        loss = criterion(unet_output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        current_loss += loss.item()\n",
    "\n",
    "        unet_output = flatten_(unet_output.detach().cpu().numpy())\n",
    "        y = flatten_(y.detach().cpu().numpy())\n",
    "        r2_score += eval_criterion(unet_output, y).item()\n",
    "\n",
    "        tq.set_description(\n",
    "            f\"Epoch {epoch} loss: {current_loss / (i + 1):.4f}, r2: {r2_score / (i + 1):.4f}\"\n",
    "        )\n",
    "\n",
    "        tq.update(1)\n",
    "    tq.close()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    current_loss = 0.0\n",
    "    r2_score = 0.0\n",
    "\n",
    "    tq = tqdm(total=len(valid_loader))\n",
    "\n",
    "    group2_stack = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(valid_loader):\n",
    "            g0 = data[\"g0\"].to(cfg.device).to(torch.float32)\n",
    "            g1 = data[\"g1\"].to(cfg.device).to(torch.float32)\n",
    "            g2 = data[\"g2\"].to(cfg.device).to(torch.float32)\n",
    "            g3 = data[\"g3\"].to(cfg.device).to(torch.float32)\n",
    "            g4 = data[\"g4\"].to(cfg.device).to(torch.float32)\n",
    "            g5 = data[\"g5\"].to(cfg.device).to(torch.float32)\n",
    "            g6 = data[\"g6\"].to(cfg.device).to(torch.float32)\n",
    "            g7 = data[\"g7\"].to(cfg.device).to(torch.float32)\n",
    "            g8 = data[\"g8\"].to(cfg.device).to(torch.float32)\n",
    "            g_else = data[\"g_else\"].to(cfg.device).to(torch.float32)\n",
    "\n",
    "            y0 = data[\"y0\"].to(cfg.device).unsqueeze(1)\n",
    "            y1 = data[\"y1\"].to(cfg.device).unsqueeze(1)\n",
    "            y2 = data[\"y2\"].to(cfg.device).unsqueeze(1)\n",
    "            y3 = data[\"y3\"].to(cfg.device).unsqueeze(1)\n",
    "            y4 = data[\"y4\"].to(cfg.device).unsqueeze(1)\n",
    "            y5 = data[\"y5\"].to(cfg.device).unsqueeze(1)\n",
    "            y6 = data[\"y6\"].to(cfg.device).unsqueeze(-1).repeat(1, 1, 60)\n",
    "            y = torch.cat([y0, y1, y2, y3, y4, y5, y6], dim=1).to(torch.float32)\n",
    "\n",
    "            unet_output = model(g0, g1, g2, g3, g4, g5, g6, g7, g8, g_else)\n",
    "            loss = criterion(unet_output, y)\n",
    "\n",
    "            pred = flatten_(unet_output.detach().cpu().numpy())\n",
    "            label = flatten_(y.detach().cpu().numpy())\n",
    "\n",
    "            valid_preds.append(pred)\n",
    "            valid_labels.append(label)\n",
    "            group2_stack.append(g1.detach().cpu().numpy())\n",
    "\n",
    "            current_loss += loss.item()\n",
    "            unet_output = flatten_(unet_output.detach().cpu().numpy())\n",
    "            y = flatten_(y.detach().cpu().numpy())\n",
    "            r2_score += eval_criterion(unet_output, y).item()\n",
    "\n",
    "            tq.set_description(\n",
    "                f\"Epoch {epoch} loss: {current_loss / (i + 1):.4f}, r2: {r2_score / (i + 1):.4f}\"\n",
    "            )\n",
    "\n",
    "            tq.update(1)\n",
    "    tq.close()\n",
    "\n",
    "    valid_preds = np.concatenate(valid_preds, axis=0)\n",
    "    valid_labels = np.concatenate(valid_labels, axis=0)\n",
    "    group2_stack = np.concatenate(group2_stack, axis=0)\n",
    "\n",
    "    for i, column in enumerate(target_columns):\n",
    "        valid_r2_scores[column] = one_column_r2(\n",
    "            valid_preds[:, i],\n",
    "            valid_labels[:, i],\n",
    "            i,\n",
    "            weight[0, i],\n",
    "        )\n",
    "\n",
    "    # ひとまず予測 & ignore_indexを取得\n",
    "    mean_score = np.mean(list(valid_r2_scores.values()))\n",
    "    for i, (key, value) in enumerate(valid_r2_scores.items()):\n",
    "        if value < 0:\n",
    "            print(f\"{i}, {key}, {value}\")\n",
    "            ignore_index.append(i)\n",
    "\n",
    "    # q0002のみルールベースで無\n",
    "    q0002_cols = []\n",
    "    for i in range(28):\n",
    "        q0002_cols.append(f\"ptend_q0002_{i}\")\n",
    "    q0002_count = 0\n",
    "\n",
    "    q0003_cols = []\n",
    "    for i in range(28):\n",
    "        q0003_cols.append(f\"ptend_q0003_{i}\")\n",
    "    q0003_count = 0\n",
    "\n",
    "    for i, column in enumerate(target_columns):\n",
    "        if column in q0002_cols:\n",
    "            valid_preds[:, i] = tmp_valid_load_data[\n",
    "                : len(valid_preds), 120 + q0002_count\n",
    "            ]\n",
    "            q0002_count += 1\n",
    "\n",
    "            valid_r2_scores[column] = ignore_one_column_r2(\n",
    "                valid_preds[:, i],\n",
    "                valid_labels[:, i],\n",
    "                i,\n",
    "                weight[0, i],\n",
    "                ptend_0002=True,\n",
    "            )\n",
    "        else:\n",
    "            valid_r2_scores[column] = ignore_one_column_r2(\n",
    "                valid_preds[:, i],\n",
    "                valid_labels[:, i],\n",
    "                i,\n",
    "                weight[0, i],\n",
    "                ptend_0002=False,\n",
    "            )\n",
    "\n",
    "    ignore_mean_score = np.mean(list(valid_r2_scores.values()))\n",
    "    print(f\"mean_score: {mean_score}, ignore_mean_score: {ignore_mean_score}\")\n",
    "\n",
    "    if ignore_mean_score > best_r2:\n",
    "        best_r2 = ignore_mean_score\n",
    "        best_model = model.state_dict()\n",
    "        torch.save(best_model, f\"./best_model.pth\")\n",
    "        pickle.dump(ignore_index, open(\"ignore_index.pkl\", \"wb\"))\n",
    "\n",
    "    graph_plot(epoch, valid_r2_scores, weight[0])\n",
    "\n",
    "    print(\"####################\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
